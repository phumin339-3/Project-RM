# app.py
import os, sys, json, traceback
from datetime import datetime
from urllib.parse import urlparse

from flask import Flask, request, jsonify, render_template
from flask_cors import CORS

import joblib
import pandas as pd
import numpy as np
from treeinterpreter import treeinterpreter as ti

# ---------------- PATHS ----------------
app_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(app_dir, ".."))
template_dir = os.path.join(project_root, "templates")

# ‡∏´‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà "‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á"
def _ensure_writable_dir(candidates):
    for d in candidates:
        try:
            os.makedirs(d, exist_ok=True)
            test_path = os.path.join(d, ".write_test")
            with open(test_path, "w", encoding="utf-8") as f:
                f.write("ok")
            os.remove(test_path)
            return d
        except Exception as e:
            print(f"[BOOT] dir not writable -> {d} ({e})")
    return None

db_dir = _ensure_writable_dir([
    os.path.join(project_root, "database"),
    "/tmp/appdata/database",
]) or "/tmp"

model_path = os.path.join(app_dir, "phishing_model.pkl")
feature_order_path = os.path.join(app_dir, "feature_order.json")
log_file_path = os.path.join(db_dir, "result_log.json")

print(f"[BOOT] db_dir   = {db_dir}")
print(f"[BOOT] log_file = {log_file_path}")

# ---------------- FLASK ----------------
app = Flask(__name__, template_folder=template_dir)
CORS(app)

# ---------------- LOAD MODEL/FEATURES ----------------
if not os.path.exists(model_path):
    raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà {model_path}")

model = joblib.load(model_path)

if os.path.exists(feature_order_path):
    with open(feature_order_path, "r", encoding="utf-8") as f:
        FEATURE_ORDER = json.load(f)
else:
    FEATURE_ORDER = None

# ---------------- IMPORT url_checker ----------------
# ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: url_checker ‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ Selenium init ‡∏ï‡∏≠‡∏ô import
sys.path.append(app_dir)
from url_checker import analyze_full_url  # ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà normalize URL ‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
# ‡πÄ‡∏û‡∏¥‡πà‡∏° normalize_url ‡πÅ‡∏ö‡∏ö local ‡πÄ‡∏ú‡∏∑‡πà‡∏≠ url_checker ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ normalize
import re
def normalize_url(u: str) -> str:
    u = (u or "").strip()
    if not u:
        return u
    if not u.startswith(("http://", "https://")):
        if re.match(r"^[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}(/|$)", u):
            return "https://" + u
        return "http://" + u
    return u

# ---------------- HUMAN READABLE ----------------
HUMAN_READABLE = {
    "length_url": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á URL",
    "length_hostname": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô",
    "ip": "‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏õ‡πá‡∏ô IP ‡πÅ‡∏ó‡∏ô‡πÇ‡∏î‡πÄ‡∏°‡∏ô",
    "punycode": "‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡πÉ‡∏ä‡πâ Punycode (xn--)",
    "ratio_digits_url": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô URL",
    "ratio_digits_host": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô",
    "nb_subdomains": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô subdomain ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏ô‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏´‡∏•‡∏±‡∏Å",
    "tld_in_path": "‡∏°‡∏µ TLD (‡πÄ‡∏ä‡πà‡∏ô .com) ‡πÑ‡∏õ‡πÇ‡∏ú‡∏•‡πà‡πÉ‡∏ô path",
    "tld_in_subdomain": "‡∏°‡∏µ TLD ‡πÑ‡∏õ‡πÇ‡∏ú‡∏•‡πà‡πÉ‡∏ô subdomain",
    "random_domain": "‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏™‡∏∏‡πà‡∏°/‡πÉ‡∏™‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç",
    "shortening_service": "‡πÄ‡∏õ‡πá‡∏ô URL ‡πÅ‡∏ö‡∏ö‡∏¢‡πà‡∏≠ (bit.ly ‡∏Ø‡∏•‡∏Ø)",
    "path_extension": "‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ô‡∏ö‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á (.exe, .zip, .php ‡∏Ø‡∏•‡∏Ø)",
    "prefix_suffix": "‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏°‡∏µ‡∏Ç‡∏µ‡∏î‡∏Å‡∏•‡∏≤‡∏á (-)",
    "phish_hints": "‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢ (login, verify, account ‡∏Ø‡∏•‡∏Ø)",
    "url_entropy": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏≠‡∏á URL",
    "uses_https": "‡πÉ‡∏ä‡πâ HTTPS (‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™)",
    "is_http": "‡πÉ‡∏ä‡πâ HTTP ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ (‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™)",
    "num_query_params": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô query parameters",
    "has_at_symbol": "‡∏°‡∏µ‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå @ ‡πÉ‡∏ô URL",
    "ssl_valid": "‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á SSL ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ",
    "cert_days_left": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô SSL ‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏",
    "san_count": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡πÉ‡∏ô‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á SSL (SAN)",
    "cert_cn_matches_domain": "‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á SSL",
    "domain_age_days": "‡∏≠‡∏≤‡∏¢‡∏∏‡πÇ‡∏î‡πÄ‡∏°‡∏ô (‡∏ß‡∏±‡∏ô)",
    "tld_risk": "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏Ç‡∏≠‡∏á TLD",
    "days_since_update": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà update ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î",
    "has_whois_privacy": "‡∏õ‡∏¥‡∏î‡∏ö‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• WHOIS",
    "redirect_chain_len": "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£ redirect",
    "final_domain_differs": "redirect ‡πÑ‡∏õ‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏≠‡∏∑‡πà‡∏ô",
    "has_security_headers": "‡∏°‡∏µ Security Headers",
    "typosquat_candidate": "‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏î‡∏±‡∏á (typosquat)",
    "typosquat_score_max": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠ (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î)",
    "typosquat_score_mean": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠ (‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢)",
    "typosquat_distance": "‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏Å‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á",
    # engineered
    "url_length_ratio": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß URL ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÇ‡∏î‡πÄ‡∏°‡∏ô",
    "digit_ratio_diff": "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á URL ‡πÅ‡∏•‡∏∞‡πÇ‡∏î‡πÄ‡∏°‡∏ô",
    "domain_age_lt_90d": "‡∏≠‡∏≤‡∏¢‡∏∏‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 90 ‡∏ß‡∏±‡∏ô",
    "ssl_invalid_or_short": "SSL ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô/‡∏à‡∏∞‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏‡πÉ‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡∏™‡∏±‡πâ‡∏ô",
    "redirect_and_domain_diff": "‡∏°‡∏µ redirect ‡πÅ‡∏•‡∏∞‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏≠‡∏∑‡πà‡∏ô",
}

BOOL_FEATS = {
    "ssl_valid","uses_https","is_http","ip","punycode","shortening_service","prefix_suffix",
    "tld_in_path","tld_in_subdomain","random_domain","phish_hints","has_at_symbol",
    "domain_age_lt_90d","ssl_invalid_or_short","redirect_and_domain_diff",
    "typosquat_candidate","has_whois_privacy","final_domain_differs","has_security_headers"
}

REDIRECT_FEATS = {"redirect_chain_len", "final_domain_differs", "redirect_and_domain_diff"}

# ---------------- HELPERS ----------------
def to_float(x, default=0.0):
    try: return float(x)
    except: return default

def to_int01(x):
    if x in (True, 1, "1"): return 1
    if x in (False, 0, "0"): return 0
    try: return 1 if float(x) != 0 else 0
    except: return 0

def build_feature_row(features_dict, feature_order):
    row = []
    for feat in feature_order:
        val = features_dict.get(feat, None)
        if feat == "domain_age_days":
            row.append(-1 if val is None else to_float(val, -1))
        elif feat in BOOL_FEATS:
            row.append(to_int01(val))
        else:
            row.append(to_float(val, 0.0))
    return row

def friendly_value(feat, v):
    if feat in BOOL_FEATS:
        return "‡∏û‡∏ö" if to_int01(v)==1 else "‡πÑ‡∏°‡πà‡∏û‡∏ö"
    if feat == "cert_cn_matches_domain":
        return "‡∏ï‡∏£‡∏á" if to_int01(v)==1 else "‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á"
    return f"{v}"

def make_explanation(feat_key, label, value_str, c):
    neg = c < 0
    if feat_key == "domain_age_days":
        return f"‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏°‡∏≤‡∏ô‡∏≤‡∏ô ({value_str} ‡∏ß‡∏±‡∏ô)" if neg else f"‡∏≠‡∏≤‡∏¢‡∏∏‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏¢‡∏±‡∏á‡πÉ‡∏´‡∏°‡πà ({value_str} ‡∏ß‡∏±‡∏ô)"
    if feat_key == "ssl_valid":
        return "‡∏û‡∏ö‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á SSL ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ" if neg else "‡πÑ‡∏°‡πà‡∏û‡∏ö/‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á SSL"
    if feat_key == "cert_days_left":
        return f"‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á SSL ‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏≠‡∏≤‡∏¢‡∏∏ {value_str} ‡∏ß‡∏±‡∏ô" if neg else f"‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á SSL ‡πÉ‡∏Å‡∏•‡πâ‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏ ({value_str} ‡∏ß‡∏±‡∏ô)"
    if feat_key == "san_count":
        return f"‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á SSL ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏î‡πÄ‡∏°‡∏ô ({value_str} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)" if neg else f"‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á SSL ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ô‡πâ‡∏≠‡∏¢ ({value_str} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)"
    if feat_key == "cert_cn_matches_domain":
        return "‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á SSL" if value_str == "‡∏ï‡∏£‡∏á" else "‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á SSL"
    if feat_key in REDIRECT_FEATS:
        return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢" if neg else "‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á/‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏≠‡∏∑‡πà‡∏ô"
    return f"{label}: {value_str}"

def _coalesce_reasons(reasons):
    grouped = {}
    for r in reasons:
        key = r["feature"]
        r2 = dict(r)
        if r["feature"] in REDIRECT_FEATS:
            direction_key = "neg" if r["contribution"] < 0 else "pos"
            key = f"redirect_group_{direction_key}"
            r2["label"] = "‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á"
            if r["contribution"] < 0:
                r2["explanation"] = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥"
                r2["value"] = "‡∏õ‡∏Å‡∏ï‡∏¥"
            else:
                r2["explanation"] = "‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ (‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏õ‡∏ï‡πà‡∏≤‡∏á‡πÇ‡∏î‡πÄ‡∏°‡∏ô)"
                r2["value"] = "‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥"
        prev = grouped.get(key)
        if (prev is None) or (abs(r2["contribution"]) > abs(prev["contribution"])):  # pick the stronger one
            grouped[key] = r2
    merged = list(grouped.values())
    merged.sort(key=lambda x: abs(x["contribution"]), reverse=True)
    return merged

def pick_top_reasons(feature_names, values_dict, contribs_for_unsafe, final_label, top_k=5):
    pairs = list(zip(feature_names, contribs_for_unsafe))
    if final_label == "unsafe":
        pairs = [p for p in pairs if p[1] > 0]
        pairs.sort(key=lambda x: x[1], reverse=True)
    else:
        pairs = [p for p in pairs if p[1] < 0]
        pairs.sort(key=lambda x: x[1])
    reasons = []
    for feat, c in pairs:
        label = HUMAN_READABLE.get(feat, feat)
        raw_v = values_dict.get(feat, None)
        v_str = friendly_value(feat, raw_v)
        explanation = make_explanation(feat, label, v_str, c)
        reasons.append({
            "feature": feat,
            "label": label,
            "value": v_str,
            "contribution": float(c),
            "explanation": explanation
        })
    reasons = _coalesce_reasons(reasons)
    return reasons[:top_k]

def classify_band(prob_unsafe: float):
    if prob_unsafe < 0.35:
        return "safe"
    if prob_unsafe < 0.65:
        return "suspicious"
    return "unsafe"

def result_message(label: str, host: str):
    if label == "safe":
        return f"{host} ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÇ‡∏õ‡∏£‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏°‡∏±‡∏î‡∏£‡∏∞‡∏ß‡∏±‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥"
    if label == "suspicious":
        return f"{host} ‡∏°‡∏µ‡∏ö‡∏≤‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡πÑ‡∏î‡πâ‡πÅ‡∏ô‡πà‡∏ä‡∏±‡∏î"
    return f"{host} ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ô‡∏µ‡πâ"

def build_website_info(feats: dict) -> dict:
    """‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡πÅ‡∏™‡∏î‡∏á ‡πÅ‡∏•‡∏∞‡∏ã‡πà‡∏≠‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
    parsed = urlparse(feats.get("url", ""))
    host = parsed.netloc or feats.get("url", "")
    info = {"‡πÇ‡∏î‡πÄ‡∏°‡∏ô": host}

    if feats.get("domain_age_days", -1) >= 0:
        info["‡∏≠‡∏≤‡∏¢‡∏∏‡πÇ‡∏î‡πÄ‡∏°‡∏ô (‡∏ß‡∏±‡∏ô)"] = feats["domain_age_days"]

    if feats.get("uses_https", 0) != 1:
        info["‡πÉ‡∏ä‡πâ HTTPS"] = "‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà"

    if feats.get("ssl_valid", 0) != 1:
        info["‡πÉ‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á SSL"] = "‡πÑ‡∏°‡πà‡∏û‡∏ö/‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"
    else:
        if feats.get("cert_days_left", 0) <= 30:
            info["SSL ‡πÉ‡∏Å‡∏•‡πâ‡∏´‡∏°‡∏î‡∏≠‡∏≤‡∏¢‡∏∏ (‡∏ß‡∏±‡∏ô)"] = feats.get("cert_days_left", 0)

    if feats.get("redirect_chain_len", 0) > 0:
        info["‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£ redirect"] = feats.get("redirect_chain_len", 0)
    if feats.get("final_domain_differs", 0) == 1:
        info["redirect ‡πÑ‡∏õ‡πÇ‡∏î‡πÄ‡∏°‡∏ô‡∏≠‡∏∑‡πà‡∏ô"] = "‡∏°‡∏µ"

    # ‡∏ñ‡πâ‡∏≤ url_checker ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏ï‡∏¥‡∏°‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏à‡∏≤‡∏Å Selenium ‡πÄ‡∏ä‡πà‡∏ô current_url/redirect_chain ‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡∏¢‡∏≤‡∏Å‡πÇ‡∏ä‡∏ß‡πå‡∏Å‡πá‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏î‡πâ:
    if feats.get("selenium_current_url"):
        info["‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå)"] = feats["selenium_current_url"]

    return info

# ---------------- LOG SAVE (atomic + fallback) ----------------
def save_log_record(record: dict) -> str:
    try:
        os.makedirs(db_dir, exist_ok=True)
        logs = []
        if os.path.exists(log_file_path) and os.path.getsize(log_file_path) > 0:
            try:
                with open(log_file_path, "r", encoding="utf-8") as f:
                    logs = json.load(f)
                    if not isinstance(logs, list):
                        logs = []
            except Exception as e:
                print(f"[LOG] read error -> reset: {e}")
        logs.append(record)
        tmp_path = log_file_path + ".tmp"
        with open(tmp_path, "w", encoding="utf-8") as f:
            json.dump(logs, f, ensure_ascii=False, indent=2)
            f.flush()
            os.fsync(f.fileno())
        os.replace(tmp_path, log_file_path)
        print(f"[LOG] appended -> {log_file_path}")
        return log_file_path
    except Exception as e:
        print(f"[LOG] write error: {e}")
        try:
            fb_dir = "/tmp/appdata/database"
            os.makedirs(fb_dir, exist_ok=True)
            fb_path = os.path.join(fb_dir, "result_log.json")
            existing = []
            if os.path.exists(fb_path) and os.path.getsize(fb_path) > 0:
                try:
                    with open(fb_path, "r", encoding="utf-8") as f:
                        existing = json.load(f)
                        if not isinstance(existing, list):
                            existing = []
                except:
                    existing = []
            existing.append(record)
            with open(fb_path, "w", encoding="utf-8") as f:
                json.dump(existing, f, ensure_ascii=False, indent=2)
            print(f"[LOG] appended (fallback) -> {fb_path}")
            return fb_path
        except Exception as e2:
            print(f"[LOG] fallback write error: {e2}")
            return ""

# ---------------- ROUTES ----------------
@app.route("/", methods=["GET"])
def home():
    index_path = os.path.join(template_dir, "index.html")
    if os.path.exists(index_path):
        return render_template("index.html")
    return jsonify({"ok": True, "message": "Phishing URL API with XAI is running."})

@app.route("/healthz", methods=["GET"])
def healthz():
    return jsonify({"status": "ok"})

@app.route("/check_url/", methods=["POST"])
def check_url():
    try:
        data = request.get_json(silent=True) or {}
        url = (data.get("url") or "").strip()
        if not url:
            return jsonify({"ok": False, "error": "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡πà‡∏á url"}), 400

        # 1) Normalize + Extract features
        url_norm = normalize_url(url)   # <<< ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡πÉ‡∏´‡πâ‡∏°‡∏µ scheme ‡πÄ‡∏™‡∏°‡∏≠
        feats = analyze_full_url(url_norm)  # url_checker ‡∏Ñ‡∏ß‡∏£ normalize ‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡πÉ‡∏™‡πà‡∏ã‡πâ‡∏≥‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢
        if feats.get("domain_age_days") is None:
            feats["domain_age_days"] = -1

        # 2) Engineered features
        feats["url_length_ratio"] = feats.get("length_url", 0) / (feats.get("length_hostname", 0) + 1)
        feats["digit_ratio_diff"] = abs(feats.get("ratio_digits_url", 0) - feats.get("ratio_digits_host", 0))
        feats["domain_age_lt_90d"] = 1 if feats.get("domain_age_days", -1) < 90 and feats.get("domain_age_days", -1) >= 0 else 0
        feats["ssl_invalid_or_short"] = 1 if (feats.get("ssl_valid", 0) == 0 or feats.get("cert_days_left", 0) < 14) else 0
        feats["redirect_and_domain_diff"] = 1 if (feats.get("redirect_chain_len", 0) > 0 and feats.get("final_domain_differs", 0) == 1) else 0

        # 3) Build row
        feature_order = FEATURE_ORDER or [k for k in feats.keys() if k != "label"]
        row = build_feature_row(feats, feature_order)
        X = pd.DataFrame([row], columns=feature_order)

        # 4) Predict -> ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏ì‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏µ‡∏Ñ‡∏•‡∏≤‡∏™‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        classes = getattr(model, "classes_", None)
        if hasattr(model, "predict_proba") and classes is not None:
            proba = model.predict_proba(X)[0]
            if len(classes) == 2:
                # ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á class=1 ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
                if 1 in classes:
                    idx1 = int(np.where(classes == 1)[0][0])
                else:
                    # fallback ‡∏õ‡∏Å‡∏ï‡∏¥ scikit ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô [0,1] ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
                    idx1 = 1
                unsafe_p = float(proba[idx1])
            else:
                # single-class model ‚Üí proba ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
                only = int(classes[0])
                unsafe_p = 1.0 if only == 1 else 0.0
        else:
            pred = int(model.predict(X)[0])
            unsafe_p = 1.0 if pred == 1 else 0.0

        final_label = classify_band(unsafe_p)

        # 5) XAI (treeinterpreter) ‚Üí ‡∏°‡∏µ fallback ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô single-class ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
        reasons = []
        bias_val = 0.0

        def _fallback_reasons_by_rules(feature_order, feats, importances, top_k=5):
            # 1) ‡∏Å‡∏é‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô: true = ‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á
            risky_rules = {
                "uses_https":              lambda v: v == 0,
                "ssl_valid":               lambda v: v == 0,
                "cert_days_left":          lambda v: v < 14,
                "domain_age_days":         lambda v: (v >= 0 and v < 90),
                "redirect_chain_len":      lambda v: v > 0,
                "final_domain_differs":    lambda v: v == 1,
                "has_at_symbol":           lambda v: v == 1,
                "shortening_service":      lambda v: v == 1,
                "phish_hints":             lambda v: v == 1,
                "tld_risk":                lambda v: v == 1,
                "url_entropy":             lambda v: v > 4.0,
                "length_url":              lambda v: v > 80,
                "num_query_params":        lambda v: v > 3,
                "prefix_suffix":           lambda v: v == 1,
                "random_domain":           lambda v: v == 1,
                "typosquat_candidate":     lambda v: v == 1,
                "ssl_invalid_or_short":    lambda v: v == 1,
                "redirect_and_domain_diff":lambda v: v == 1,
            }

            # 2) ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ/‡πÄ‡∏õ‡πá‡∏ô‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            default_weights = {
                "ssl_valid": 1.0, "uses_https": 0.9, "ssl_invalid_or_short": 0.9,
                "cert_days_left": 0.8, "domain_age_days": 0.8, "domain_age_lt_90d": 0.8,
                "final_domain_differs": 0.8, "redirect_and_domain_diff": 0.75, "redirect_chain_len": 0.6,
                "phish_hints": 0.8, "typosquat_candidate": 0.7, "random_domain": 0.7,
                "length_url": 0.55, "url_entropy": 0.55, "num_query_params": 0.5,
                "shortening_service": 0.5, "has_at_symbol": 0.45, "prefix_suffix": 0.45,
                "tld_risk": 0.5,
            }

            # 3) ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ
            use_default = True
            weights = {}
            if importances is not None:
                try:
                    imp_arr = np.asarray(importances).astype(float)
                    if np.any(imp_arr > 0):
                        use_default = False
                        for i, feat in enumerate(feature_order):
                            if feat == "label": 
                                continue
                            w = float(imp_arr[i]) if i < len(imp_arr) else 0.0
                            weights[feat] = w
                except Exception:
                    use_default = True

            if use_default:
                # ‡πÉ‡∏ä‡πâ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏° domain knowledge
                for feat in feature_order:
                    if feat == "label": 
                        continue
                    weights[feat] = default_weights.get(feat, 0.2)

            # 4) ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏≠‡∏á w==0 ‡∏ó‡∏¥‡πâ‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÄ‡∏™‡∏°‡∏≠
            scored = []
            for feat in feature_order:
                if feat == "label": 
                    continue
                v = feats.get(feat, 0)
                w = float(weights.get(feat, 0.2))
                is_risky = risky_rules.get(feat, lambda _: False)(v)
                # ‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á = ‡∏ö‡∏ß‡∏Å, ‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á = ‡∏•‡∏ö (‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤)
                score = w * (1.0 if is_risky else -0.4)
                label = HUMAN_READABLE.get(feat, feat)
                expl = f"{label}: {'‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πà‡∏≤‡∏¢‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á' if is_risky else '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô'}"
                scored.append({
                    "feature": feat,
                    "label": label,
                    "value": friendly_value(feat, v),
                    "score": score,
                    "explanation": expl
                })

            # ‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö ‚Üí ‡πÄ‡∏≠‡∏≤ ‚Äú‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‚Äù ‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢ ‚Äú‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‚Äù
            scored.sort(key=lambda x: x["score"], reverse=True)

            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á 3 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‚Äú‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‚Äù ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏ï‡πâ‡∏ô ‡πÜ ‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
            positives = [s for s in scored if s["score"] > 0]
            if not positives:
                positives = [s for s in scored if s["score"] < 0][:3]

            out = []
            for r in positives[:top_k]:
                out.append({
                    "feature": r["feature"],
                    "label": r["label"],
                    "value": r["value"],
                    "contribution": float(r["score"]),
                    "explanation": r["explanation"]
                })
            return out

        try:
            # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÉ‡∏ä‡πâ treeinterpreter ‡∏Å‡πà‡∏≠‡∏ô
            _, bias, contribs = ti.predict(model, X.values)
            classes = getattr(model, "classes_", None)
            if contribs.ndim == 3 and classes is not None and (len(classes) >= 2) and (1 in classes):
                idx1 = int(np.where(classes == 1)[0][0])
                contrib_unsafe = contribs[0, :, idx1]
                reasons = pick_top_reasons(
                    feature_order, feats, contrib_unsafe,
                    "unsafe" if unsafe_p >= 0.5 else "safe",
                    top_k=5
                )
                bias_val = float(bias[0, idx1])
            else:
                # ‚ùó Fallback: ‡πÉ‡∏ä‡πâ importances + rules (‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà)
                importances = getattr(model, "feature_importances_", None)
                reasons = _fallback_reasons_by_rules(feature_order, feats, importances, top_k=5)
                bias_val = 0.0
        except Exception:
            # ‡∏ñ‡πâ‡∏≤ XAI ‡∏û‡∏±‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‚Üí fallback ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô
            importances = getattr(model, "feature_importances_", None)
            reasons = _fallback_reasons_by_rules(feature_order, feats, importances, top_k=5)
            bias_val = 0.0


        # 6) Website Info
        website_info = build_website_info(feats)

        # 7) Message
        parsed = urlparse(feats.get("url", url_norm))
        host = parsed.netloc or feats.get("url", url_norm)
        message = result_message(final_label, host)

        # 8) Log
        record = {
            "url": feats.get("url", url_norm),
            "timestamp": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
            "result": final_label,
            "unsafe_probability": round(unsafe_p, 4),
            "reasons": reasons,
            "website_info": website_info,
        }
        log_path_used = save_log_record(record)

        # 9) Response
        return jsonify({
            "ok": True,
            "url": feats.get("url", url_norm),
            "timestamp": datetime.utcnow().isoformat(),
            "result": final_label,
            "message": message,
            "website_info": website_info,
            "reasons": reasons,
            "bias": bias_val,
            "log_path": log_path_used,
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500

@app.route("/disclaimerPopup.html", methods=["GET"])
def disclaimer_popup():
    return render_template("disclaimerPopup.html")

@app.route("/save_disclaimer", methods=["POST"])
def save_disclaimer():
    try:
        data = request.get_json()
        disclaimer_file_path = os.path.join(db_dir, "disclaimer.json")
        if os.path.exists(disclaimer_file_path):
            with open(disclaimer_file_path, "r", encoding="utf-8") as f:
                try:
                    disclaimers = json.load(f)
                except json.JSONDecodeError:
                    disclaimers = []
        else:
            disclaimers = []
        disclaimers.append(data)
        with open(disclaimer_file_path, "w", encoding="utf-8") as f:
            json.dump(disclaimers, f, ensure_ascii=False, indent=2)
        return jsonify({"ok": True, "message": "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß!"}), 200
    except Exception as e:
        print(f"Error saving disclaimer: {e}")
        return jsonify({"ok": False, "error": str(e)}), 500

if __name__ == "__main__":
    print("üìÇ template_dir:", template_dir)
    print("üì¶ model_path:", model_path)
    app.run(host="0.0.0.0", port=5000, debug=True)
